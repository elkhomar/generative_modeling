# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: lafan_rot6d.yaml
  - override /model: beta_vae_rot6d_loss.yaml
  - override /trainer: default.yaml
#  - override /logger: wandb.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["no translation", "beta_vae", "rot6d standard loss", "latent_dim = ${model.latent_dim}", "sequence_length = ${data.seq_len}"]

seed: 42


trainer:
  min_epochs: 90
  max_epochs: 100

model:
  optimizer:
    lr: 0.001
  beta : 0.002

data:
  seq_len: 2
  batch_size: 64

#  